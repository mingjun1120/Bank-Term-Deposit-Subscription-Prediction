data: 
  train_path: data/train.csv
  test_path: data/test.csv

train:
  test_size: 0.2
  random_state: 42
  shuffle: true

# You can test out multiple models by adding them to the config file or same model with different hyperparameters
model:
  name: LGBMClassifier
  
  params:
    objective: binary
    random_state: 42
    is_unbalance: true
    n_jobs: -1
    boosting_type: gbdt

  tuning_params:
    model__n_estimators: [50, 100, 150]
    model__learning_rate: [0.01, 0.1]
    model__max_depth: [-1]
  
  k_fold: 
    n_splits: 5
    shuffle: true
    random_state: 42

  store_path: models/

  # name: GradientBoostingClassifier
  # params:
  #   max_depth: null
  #   n_estimators: 10
  # store_path: models/

  # name: RandomForestClassifier
  # params:
  #   n_estimators: 50
  #   max_depth: 10
  #   random_state: 42
  # store_path: models/